import numpy as np
import cv2

# Parameters
blur = 21
canny_low = 15
canny_high = 150
min_area = 0.0005
max_area = 0.95
dilate_iter = 10
erode_iter = 10
mask_color = (0, 0, 0)   # black color

# initialize video from the webcam
video = cv2.VideoCapture(0)

# create a boolean variable for keeping track of the previous hand position
hand_in_top_right = False

while True:
    ret, frame = video.read()
    
    if ret == True:
        # Convert image to grayscale        
        image_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # Apply Canny Edge Dection
        edges = cv2.Canny(image_gray, canny_low, canny_high)

        edges = cv2.dilate(edges, None)
        edges = cv2.erode(edges, None)  

        # get the contours and their areas
        contours = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[0]
        if len(contours) > 0:
            contour_info = [(c, cv2.contourArea(c),) for c in contours]
            # Get the area of the image as a comparison
            image_area = frame.shape[0] * frame.shape[1]  
          
            # calculate max and min areas in terms of pixels
            max_area_pixels = int(max_area * image_area)
            min_area_pixels = int(min_area * image_area)        
        
            # Set up mask with a matrix of 0's
            mask = np.zeros(edges.shape, dtype=np.uint8)
            
            # Go through and find relevant contours and apply to mask
            for contour in contour_info:
                # Instead of worrying about all the smaller contours, if the area is smaller than the min, the loop will break
                if contour[1] > min_area_pixels and contour[1] < max_area_pixels:
                    # Add contour to mask
                    mask = cv2.fillConvexPoly(mask, contour[0], (255))

            # Get the dimensions of the frame
            height, width, channels = frame.shape

            # Check if hand is in the top right corner
            top_right = mask[0:int(height/8), int(7*width/8):width]
            if cv2.countNonZero(top_right) > 0:
                # use dilate, erode, and blur to smooth out the mask
                mask = cv2.dilate(mask, None, iterations=dilate_iter)
                mask = cv2.erode(mask, None, iterations=erode_iter)
                mask = cv2.GaussianBlur(mask, (blur, blur), 0)

                # Convert single-channel mask to three-channel for matcing the dimensions of the frame
                mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)

                # Ensures data types match up
                mask = mask.astype('float32') / 255.0           
                frame = frame.astype('float32') / 255.0

                # Blur the background by blending the frame and the blurred mask color
                blurred_mask_color = cv2.GaussianBlur(frame, (blur, blur), 0)
                background = (1 - mask) * blurred_mask_color + mask * frame
                
                # Flip the mirrored background horizontally
                background = cv2.flip(background, 1)
                
                # Display the blurred background frame
                cv2.imshow("Frame", background)
                hand_in_top_right = True
            else:
                # Flip the raw frame horizontally
                frame = cv2.flip(frame, 1)

                # Display the raw frame
                cv2.imshow("Frame", frame)
                hand_in_top_right = False

            # Use the q button to quit the operation
            if cv2.waitKey(60) & 0xff == ord('q'):
                break
        else:
            # Flip the raw frame horizontally
            frame = cv2.flip(frame, 1)

            # Display the raw frame
            cv2.imshow("Frame", frame)
            hand_in_top_right = False
    
    else:
        print("Error reading from video capture device.")
        break

cv2.destroyAllWindows()
video.release()
